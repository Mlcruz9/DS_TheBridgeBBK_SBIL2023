{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras\n",
    "Librería para programar redes neuronales de una manera más sencilla que con TensorFlow. Keras se encuentra en una capa de abstracción por encima de TensorFlow.\n",
    "\n",
    "[Documentación](https://keras.io/guides/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow\n",
    "# !pip install keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezamos importando librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos de mnist. No vamos a tratar imagenes con redes convolucionales (perdemos la estructura espacial 2D). Todos los pixeles se convertirán en un vector de 28x28 features independientes, que serán las entradas del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cogemos las imágenes de los dígitos asi como el conjunto de train y test\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos dimensiones del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "60.000 imagenes de 28x28 pixeles\n",
    "'''\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "60.000 imágenes de 28x28 pixeles. Vamos a representar una de ellas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\misla\\AppData\\Local\\Temp\\ipykernel_11448\\3096108358.py:3: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  plt.imshow(X_train[0], cmap=plt.cm.get_cmap('Greys'));\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(X_train[0], cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada imagen se compone de 28x28 pixeles, y cada pixel representa una escala de grises que va del 0 al 255. Siendo 0 el blanco y 255 negro.\n",
    "\n",
    "¿Se te ocurre alguna manera de normalizar los datos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5019607843137255"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "128/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "255/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(\"float32\")/255\n",
    "X_test = X_test.astype(\"float32\")/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13066062"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "        0.07058824, 0.49411765, 0.53333336, 0.6862745 , 0.10196079,\n",
       "        0.6509804 , 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.11764706, 0.14117648,\n",
       "        0.36862746, 0.6039216 , 0.6666667 , 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.88235295, 0.6745098 ,\n",
       "        0.99215686, 0.9490196 , 0.7647059 , 0.2509804 , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.19215687, 0.93333334, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.9843137 , 0.3647059 , 0.32156864,\n",
       "        0.32156864, 0.21960784, 0.15294118, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.07058824, 0.85882354, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.7764706 ,\n",
       "        0.7137255 , 0.96862745, 0.94509804, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.3137255 , 0.6117647 ,\n",
       "        0.41960785, 0.99215686, 0.99215686, 0.8039216 , 0.04313726,\n",
       "        0.        , 0.16862746, 0.6039216 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "        0.00392157, 0.6039216 , 0.99215686, 0.3529412 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.54509807, 0.99215686, 0.74509805, 0.00784314,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.04313726, 0.74509805, 0.99215686, 0.27450982,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.13725491, 0.94509804, 0.88235295,\n",
       "        0.627451  , 0.42352942, 0.00392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31764707, 0.9411765 ,\n",
       "        0.99215686, 0.99215686, 0.46666667, 0.09803922, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.1764706 ,\n",
       "        0.7294118 , 0.99215686, 0.99215686, 0.5882353 , 0.10588235,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0627451 , 0.3647059 , 0.9882353 , 0.99215686, 0.73333335,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.9764706 , 0.99215686, 0.9764706 ,\n",
       "        0.2509804 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.18039216,\n",
       "        0.50980395, 0.7176471 , 0.99215686, 0.99215686, 0.8117647 ,\n",
       "        0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15294118, 0.5803922 , 0.8980392 ,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.98039216, 0.7137255 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.09411765, 0.44705883, 0.8666667 , 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.7882353 , 0.30588236, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.09019608, 0.25882354,\n",
       "        0.8352941 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.7764706 , 0.31764707, 0.00784314, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.07058824, 0.67058825, 0.85882354, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.7647059 , 0.3137255 ,\n",
       "        0.03529412, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.21568628,\n",
       "        0.6745098 , 0.8862745 , 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.95686275, 0.52156866, 0.04313726, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.53333336,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.83137256, 0.5294118 ,\n",
       "        0.5176471 , 0.0627451 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Comprobamos la normalización\n",
    "'''\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype(\"float32\")\n",
    "y_test = y_test.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos datos para validación. Estos datos se usarán durante el entrenamiento. Otra opción es decirle a keras en la etapa de entrenamiento que reserve un X % de los datos para validar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "\n",
    "X_train = X_train[:-10000]\n",
    "y_train = y_train[:-10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montamos la arquitectura de la red neuronal. Se va a componer de:\n",
    "* **Sequential**: API para iniciar la red neuronal. No cuenta como capa.\n",
    "* **Flatten**: capa de entrada. Necesita un vector unidimensional. Como tenemos imágenes, esta capa aplana las imagenes (2D) en 1D.\n",
    "* **Dense**: es una hidden layer. Se compondrá de `n` neuronas y de una función de activación que se aplicará a todas las neuronas de la capa.\n",
    "\n",
    "Recuerda que es un problema de clasificación multiclase (10 clases) y que por tanto la última capa se compondrá de tantas neuronas como clases tengas.\n",
    "\n",
    "En cuanto a las funciones de activación es recomendable usar relu en las hidden layer, que tarda menos en entrenar, mientras que la ultima (output) suele ser una softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 28, 28)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "# Capa entrada\n",
    "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "\n",
    "# Hidden layer\n",
    "model.add(keras.layers.Dense(units = 300,\n",
    "                            activation='relu'))\n",
    "\n",
    "# Hidden layer\n",
    "model.add(keras.layers.Dense(units = 100,\n",
    "                            activation='relu'))\n",
    "\n",
    "# Capa salida\n",
    "model.add(keras.layers.Dense(units = 10,\n",
    "                            activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otra manera de declarar la red neuronal\n",
    "capas = [\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(units = 300, activation='relu'),\n",
    "    keras.layers.Dense(units = 100, activation='relu'),\n",
    "    keras.layers.Dense(units = 10, activation='softmax')\n",
    "]\n",
    "\n",
    "model = keras.models.Sequential(capas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver las capas, y acceder a sus elementos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.src.layers.reshaping.flatten.Flatten object at 0x0000019080271F60>\n"
     ]
    }
   ],
   "source": [
    "print(model.layers[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver los pesos de las capas sin entrenar, porque los inicializa aleatoriamente. Los bias los inicializa a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = model.layers[1]\n",
    "weights, biases = hidden1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 300)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weights[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235200"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "300*784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235200"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establecemos la configuración de ejecución... el compile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = keras.optimizers.SGD(),\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equivalente\n",
    "model.compile(\n",
    "    optimizer = \"sgd\",\n",
    "    loss = \"sparse_categorical_crossentropy\",\n",
    "    metrics = [\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266610 (1.02 MB)\n",
      "Trainable params: 266610 (1.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235500\n"
     ]
    }
   ],
   "source": [
    "# 1º neurona de la 1º hidden layer\n",
    "# y = a + w1*x1 + w2*x2 + .... wn*xn\n",
    "# a es el intercepto llamado bias\n",
    "# wn es cada uno de los pesos que va a ir actualizando con el backpropagation\n",
    "# n es 784\n",
    "# En la 1º hidden layer tenemos 784 pesos por cada neurona, al tener 300, tenemos un total de:\n",
    "print(784*300 + 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235500"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "300 * 784 + 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30100"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "300 * 100 + 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1010"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 * 10 + 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo. Usamos los datos de entrenamiento. El batch_size es la cantidad de muestras que utiliza el SGD, y las epochs son las iteraciones que realiza en el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 28, 28)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312.5"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "40000/128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "391/391 [==============================] - 4s 8ms/step - loss: 1.2961 - accuracy: 0.6754 - val_loss: 0.6117 - val_accuracy: 0.8692\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.5237 - accuracy: 0.8700 - val_loss: 0.3958 - val_accuracy: 0.9007\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.3991 - accuracy: 0.8927 - val_loss: 0.3316 - val_accuracy: 0.9110\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.3486 - accuracy: 0.9037 - val_loss: 0.3010 - val_accuracy: 0.9173\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.3188 - accuracy: 0.9108 - val_loss: 0.2804 - val_accuracy: 0.9215\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.2975 - accuracy: 0.9167 - val_loss: 0.2653 - val_accuracy: 0.9255\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.2809 - accuracy: 0.9216 - val_loss: 0.2510 - val_accuracy: 0.9298\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.2673 - accuracy: 0.9245 - val_loss: 0.2416 - val_accuracy: 0.9318\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.2556 - accuracy: 0.9278 - val_loss: 0.2320 - val_accuracy: 0.9344\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.2448 - accuracy: 0.9309 - val_loss: 0.2250 - val_accuracy: 0.9360\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.2352 - accuracy: 0.9338 - val_loss: 0.2168 - val_accuracy: 0.9393\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.2266 - accuracy: 0.9366 - val_loss: 0.2106 - val_accuracy: 0.9411\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.2184 - accuracy: 0.9382 - val_loss: 0.2041 - val_accuracy: 0.9421\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.2108 - accuracy: 0.9412 - val_loss: 0.1964 - val_accuracy: 0.9451\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.2037 - accuracy: 0.9427 - val_loss: 0.1914 - val_accuracy: 0.9464\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1968 - accuracy: 0.9453 - val_loss: 0.1871 - val_accuracy: 0.9488\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1906 - accuracy: 0.9463 - val_loss: 0.1808 - val_accuracy: 0.9515\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.1845 - accuracy: 0.9481 - val_loss: 0.1761 - val_accuracy: 0.9524\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1786 - accuracy: 0.9501 - val_loss: 0.1732 - val_accuracy: 0.9537\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.1731 - accuracy: 0.9518 - val_loss: 0.1673 - val_accuracy: 0.9542\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1681 - accuracy: 0.9525 - val_loss: 0.1643 - val_accuracy: 0.9559\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1631 - accuracy: 0.9542 - val_loss: 0.1599 - val_accuracy: 0.9573\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1586 - accuracy: 0.9554 - val_loss: 0.1558 - val_accuracy: 0.9582\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1539 - accuracy: 0.9564 - val_loss: 0.1533 - val_accuracy: 0.9593\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.1496 - accuracy: 0.9577 - val_loss: 0.1504 - val_accuracy: 0.9600\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1456 - accuracy: 0.9590 - val_loss: 0.1472 - val_accuracy: 0.9606\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1418 - accuracy: 0.9606 - val_loss: 0.1449 - val_accuracy: 0.9615\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1381 - accuracy: 0.9615 - val_loss: 0.1412 - val_accuracy: 0.9614\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1344 - accuracy: 0.9622 - val_loss: 0.1395 - val_accuracy: 0.9619\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1310 - accuracy: 0.9629 - val_loss: 0.1373 - val_accuracy: 0.9634\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1278 - accuracy: 0.9637 - val_loss: 0.1343 - val_accuracy: 0.9634\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1247 - accuracy: 0.9651 - val_loss: 0.1319 - val_accuracy: 0.9634\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1217 - accuracy: 0.9654 - val_loss: 0.1303 - val_accuracy: 0.9655\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1188 - accuracy: 0.9669 - val_loss: 0.1281 - val_accuracy: 0.9646\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1160 - accuracy: 0.9675 - val_loss: 0.1260 - val_accuracy: 0.9655\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1135 - accuracy: 0.9679 - val_loss: 0.1243 - val_accuracy: 0.9671\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1109 - accuracy: 0.9689 - val_loss: 0.1222 - val_accuracy: 0.9669\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1083 - accuracy: 0.9691 - val_loss: 0.1219 - val_accuracy: 0.9676\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1060 - accuracy: 0.9703 - val_loss: 0.1205 - val_accuracy: 0.9677\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1036 - accuracy: 0.9713 - val_loss: 0.1179 - val_accuracy: 0.9680\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1013 - accuracy: 0.9716 - val_loss: 0.1163 - val_accuracy: 0.9687\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.0992 - accuracy: 0.9720 - val_loss: 0.1143 - val_accuracy: 0.9695\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0970 - accuracy: 0.9727 - val_loss: 0.1133 - val_accuracy: 0.9696\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0950 - accuracy: 0.9737 - val_loss: 0.1131 - val_accuracy: 0.9701\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0931 - accuracy: 0.9740 - val_loss: 0.1107 - val_accuracy: 0.9706\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0911 - accuracy: 0.9746 - val_loss: 0.1098 - val_accuracy: 0.9706\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0892 - accuracy: 0.9756 - val_loss: 0.1089 - val_accuracy: 0.9715\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0875 - accuracy: 0.9760 - val_loss: 0.1081 - val_accuracy: 0.9711\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0858 - accuracy: 0.9765 - val_loss: 0.1081 - val_accuracy: 0.9711\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0841 - accuracy: 0.9768 - val_loss: 0.1062 - val_accuracy: 0.9718\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size = 128,\n",
    "    epochs = 50,\n",
    "    validation_data = (X_val, y_val) # validation_split = 0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos reentrenar el modelo. No empieza de nuevo, sino que retoma el entrenamiento anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.0834 - accuracy: 0.9771 - val_loss: 0.1054 - val_accuracy: 0.9721\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.0801 - accuracy: 0.9781 - val_loss: 0.1020 - val_accuracy: 0.9718\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.0771 - accuracy: 0.9789 - val_loss: 0.1043 - val_accuracy: 0.9711\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.0746 - accuracy: 0.9799 - val_loss: 0.0994 - val_accuracy: 0.9725\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.0718 - accuracy: 0.9802 - val_loss: 0.0971 - val_accuracy: 0.9733\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.0693 - accuracy: 0.9810 - val_loss: 0.0972 - val_accuracy: 0.9739\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.0667 - accuracy: 0.9820 - val_loss: 0.0978 - val_accuracy: 0.9731\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.0645 - accuracy: 0.9827 - val_loss: 0.0946 - val_accuracy: 0.9750\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.0622 - accuracy: 0.9836 - val_loss: 0.0925 - val_accuracy: 0.9741\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.0600 - accuracy: 0.9841 - val_loss: 0.0979 - val_accuracy: 0.9728\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1908304c1c0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size = 64,\n",
    "    epochs = 10,\n",
    "    validation_data = (X_val, y_val) # validation_split = 0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos el histórico del entrenamiento, para poder representarlo posteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [1.2960835695266724, 0.523692786693573, 0.3991183638572693, 0.34864071011543274, 0.31880810856819153, 0.2974894344806671, 0.28086191415786743, 0.26734721660614014, 0.2556385099887848, 0.24482500553131104, 0.23519682884216309, 0.22660759091377258, 0.21841230988502502, 0.21080265939235687, 0.20371292531490326, 0.1967771351337433, 0.19059531390666962, 0.18446063995361328, 0.17858347296714783, 0.17308826744556427, 0.16811245679855347, 0.16313259303569794, 0.15857617557048798, 0.1538960486650467, 0.14958272874355316, 0.14564132690429688, 0.1417824774980545, 0.13808798789978027, 0.13440169394016266, 0.13097697496414185, 0.12779057025909424, 0.124705471098423, 0.12174099683761597, 0.11878020316362381, 0.11604716628789902, 0.11348229646682739, 0.11088123172521591, 0.10829144716262817, 0.10595633089542389, 0.10363288968801498, 0.1013030931353569, 0.09917090088129044, 0.09704326093196869, 0.09498287737369537, 0.09305047243833542, 0.09107375144958496, 0.08921965211629868, 0.08748041093349457, 0.08581522107124329, 0.08408014476299286], 'accuracy': [0.6754000186920166, 0.8700000047683716, 0.89274001121521, 0.9037200212478638, 0.9107599854469299, 0.9166600108146667, 0.9216399788856506, 0.9244999885559082, 0.9277799725532532, 0.930899977684021, 0.9337800145149231, 0.9366400241851807, 0.9382200241088867, 0.9411600232124329, 0.9427199959754944, 0.9452800154685974, 0.946340024471283, 0.9480800032615662, 0.9500600099563599, 0.9517599940299988, 0.9525399804115295, 0.9541599750518799, 0.9554200172424316, 0.9564200043678284, 0.9576799869537354, 0.9590399861335754, 0.9605600237846375, 0.9614999890327454, 0.9622399806976318, 0.962939977645874, 0.963699996471405, 0.9650599956512451, 0.9654399752616882, 0.9668599963188171, 0.9674800038337708, 0.9679200053215027, 0.9689199924468994, 0.9690999984741211, 0.9703199863433838, 0.9712600111961365, 0.9716399908065796, 0.9720399975776672, 0.9727200269699097, 0.9736800193786621, 0.9739999771118164, 0.9745799899101257, 0.9755600094795227, 0.9760400056838989, 0.9764800071716309, 0.9768199920654297], 'val_loss': [0.6117112040519714, 0.3958372175693512, 0.3316095471382141, 0.30095985531806946, 0.2804069221019745, 0.2652668058872223, 0.25103721022605896, 0.24161256849765778, 0.2319636046886444, 0.22499394416809082, 0.21675117313861847, 0.21061892807483673, 0.20412124693393707, 0.19643452763557434, 0.19138556718826294, 0.18714934587478638, 0.18080569803714752, 0.1761285364627838, 0.17318297922611237, 0.1672688126564026, 0.16426829993724823, 0.15985961258411407, 0.1557852029800415, 0.1533459573984146, 0.15039053559303284, 0.14724531769752502, 0.14486628770828247, 0.14122213423252106, 0.1395493447780609, 0.1373126059770584, 0.1343226283788681, 0.13186335563659668, 0.13029666244983673, 0.12806998193264008, 0.1260005682706833, 0.1242535412311554, 0.12219339609146118, 0.12185125797986984, 0.12046045809984207, 0.11786458641290665, 0.11633066087961197, 0.1143348291516304, 0.11329863220453262, 0.1131104975938797, 0.11074493080377579, 0.1098318099975586, 0.10885010659694672, 0.10807519406080246, 0.10812685638666153, 0.10623423755168915], 'val_accuracy': [0.8691999912261963, 0.9006999731063843, 0.9110000133514404, 0.9172999858856201, 0.921500027179718, 0.9254999756813049, 0.9297999739646912, 0.9318000078201294, 0.9344000220298767, 0.9359999895095825, 0.939300000667572, 0.941100001335144, 0.9420999884605408, 0.9451000094413757, 0.946399986743927, 0.9488000273704529, 0.9514999985694885, 0.9524000287055969, 0.9537000060081482, 0.954200029373169, 0.9559000134468079, 0.9573000073432922, 0.9581999778747559, 0.9592999815940857, 0.9599999785423279, 0.9606000185012817, 0.9614999890327454, 0.9613999724388123, 0.961899995803833, 0.9634000062942505, 0.9634000062942505, 0.9634000062942505, 0.965499997138977, 0.9646000266075134, 0.965499997138977, 0.9671000242233276, 0.9668999910354614, 0.9675999879837036, 0.9677000045776367, 0.9679999947547913, 0.9686999917030334, 0.9695000052452087, 0.9696000218391418, 0.9700999855995178, 0.9706000089645386, 0.9706000089645386, 0.9714999794960022, 0.9710999727249146, 0.9710999727249146, 0.9718000292778015]}\n"
     ]
    }
   ],
   "source": [
    "# print(history.params)\n",
    "# print(history.epoch)\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [1.2960835695266724,\n",
       "  0.523692786693573,\n",
       "  0.3991183638572693,\n",
       "  0.34864071011543274,\n",
       "  0.31880810856819153,\n",
       "  0.2974894344806671,\n",
       "  0.28086191415786743,\n",
       "  0.26734721660614014,\n",
       "  0.2556385099887848,\n",
       "  0.24482500553131104,\n",
       "  0.23519682884216309,\n",
       "  0.22660759091377258,\n",
       "  0.21841230988502502,\n",
       "  0.21080265939235687,\n",
       "  0.20371292531490326,\n",
       "  0.1967771351337433,\n",
       "  0.19059531390666962,\n",
       "  0.18446063995361328,\n",
       "  0.17858347296714783,\n",
       "  0.17308826744556427,\n",
       "  0.16811245679855347,\n",
       "  0.16313259303569794,\n",
       "  0.15857617557048798,\n",
       "  0.1538960486650467,\n",
       "  0.14958272874355316,\n",
       "  0.14564132690429688,\n",
       "  0.1417824774980545,\n",
       "  0.13808798789978027,\n",
       "  0.13440169394016266,\n",
       "  0.13097697496414185,\n",
       "  0.12779057025909424,\n",
       "  0.124705471098423,\n",
       "  0.12174099683761597,\n",
       "  0.11878020316362381,\n",
       "  0.11604716628789902,\n",
       "  0.11348229646682739,\n",
       "  0.11088123172521591,\n",
       "  0.10829144716262817,\n",
       "  0.10595633089542389,\n",
       "  0.10363288968801498,\n",
       "  0.1013030931353569,\n",
       "  0.09917090088129044,\n",
       "  0.09704326093196869,\n",
       "  0.09498287737369537,\n",
       "  0.09305047243833542,\n",
       "  0.09107375144958496,\n",
       "  0.08921965211629868,\n",
       "  0.08748041093349457,\n",
       "  0.08581522107124329,\n",
       "  0.08408014476299286],\n",
       " 'accuracy': [0.6754000186920166,\n",
       "  0.8700000047683716,\n",
       "  0.89274001121521,\n",
       "  0.9037200212478638,\n",
       "  0.9107599854469299,\n",
       "  0.9166600108146667,\n",
       "  0.9216399788856506,\n",
       "  0.9244999885559082,\n",
       "  0.9277799725532532,\n",
       "  0.930899977684021,\n",
       "  0.9337800145149231,\n",
       "  0.9366400241851807,\n",
       "  0.9382200241088867,\n",
       "  0.9411600232124329,\n",
       "  0.9427199959754944,\n",
       "  0.9452800154685974,\n",
       "  0.946340024471283,\n",
       "  0.9480800032615662,\n",
       "  0.9500600099563599,\n",
       "  0.9517599940299988,\n",
       "  0.9525399804115295,\n",
       "  0.9541599750518799,\n",
       "  0.9554200172424316,\n",
       "  0.9564200043678284,\n",
       "  0.9576799869537354,\n",
       "  0.9590399861335754,\n",
       "  0.9605600237846375,\n",
       "  0.9614999890327454,\n",
       "  0.9622399806976318,\n",
       "  0.962939977645874,\n",
       "  0.963699996471405,\n",
       "  0.9650599956512451,\n",
       "  0.9654399752616882,\n",
       "  0.9668599963188171,\n",
       "  0.9674800038337708,\n",
       "  0.9679200053215027,\n",
       "  0.9689199924468994,\n",
       "  0.9690999984741211,\n",
       "  0.9703199863433838,\n",
       "  0.9712600111961365,\n",
       "  0.9716399908065796,\n",
       "  0.9720399975776672,\n",
       "  0.9727200269699097,\n",
       "  0.9736800193786621,\n",
       "  0.9739999771118164,\n",
       "  0.9745799899101257,\n",
       "  0.9755600094795227,\n",
       "  0.9760400056838989,\n",
       "  0.9764800071716309,\n",
       "  0.9768199920654297],\n",
       " 'val_loss': [0.6117112040519714,\n",
       "  0.3958372175693512,\n",
       "  0.3316095471382141,\n",
       "  0.30095985531806946,\n",
       "  0.2804069221019745,\n",
       "  0.2652668058872223,\n",
       "  0.25103721022605896,\n",
       "  0.24161256849765778,\n",
       "  0.2319636046886444,\n",
       "  0.22499394416809082,\n",
       "  0.21675117313861847,\n",
       "  0.21061892807483673,\n",
       "  0.20412124693393707,\n",
       "  0.19643452763557434,\n",
       "  0.19138556718826294,\n",
       "  0.18714934587478638,\n",
       "  0.18080569803714752,\n",
       "  0.1761285364627838,\n",
       "  0.17318297922611237,\n",
       "  0.1672688126564026,\n",
       "  0.16426829993724823,\n",
       "  0.15985961258411407,\n",
       "  0.1557852029800415,\n",
       "  0.1533459573984146,\n",
       "  0.15039053559303284,\n",
       "  0.14724531769752502,\n",
       "  0.14486628770828247,\n",
       "  0.14122213423252106,\n",
       "  0.1395493447780609,\n",
       "  0.1373126059770584,\n",
       "  0.1343226283788681,\n",
       "  0.13186335563659668,\n",
       "  0.13029666244983673,\n",
       "  0.12806998193264008,\n",
       "  0.1260005682706833,\n",
       "  0.1242535412311554,\n",
       "  0.12219339609146118,\n",
       "  0.12185125797986984,\n",
       "  0.12046045809984207,\n",
       "  0.11786458641290665,\n",
       "  0.11633066087961197,\n",
       "  0.1143348291516304,\n",
       "  0.11329863220453262,\n",
       "  0.1131104975938797,\n",
       "  0.11074493080377579,\n",
       "  0.1098318099975586,\n",
       "  0.10885010659694672,\n",
       "  0.10807519406080246,\n",
       "  0.10812685638666153,\n",
       "  0.10623423755168915],\n",
       " 'val_accuracy': [0.8691999912261963,\n",
       "  0.9006999731063843,\n",
       "  0.9110000133514404,\n",
       "  0.9172999858856201,\n",
       "  0.921500027179718,\n",
       "  0.9254999756813049,\n",
       "  0.9297999739646912,\n",
       "  0.9318000078201294,\n",
       "  0.9344000220298767,\n",
       "  0.9359999895095825,\n",
       "  0.939300000667572,\n",
       "  0.941100001335144,\n",
       "  0.9420999884605408,\n",
       "  0.9451000094413757,\n",
       "  0.946399986743927,\n",
       "  0.9488000273704529,\n",
       "  0.9514999985694885,\n",
       "  0.9524000287055969,\n",
       "  0.9537000060081482,\n",
       "  0.954200029373169,\n",
       "  0.9559000134468079,\n",
       "  0.9573000073432922,\n",
       "  0.9581999778747559,\n",
       "  0.9592999815940857,\n",
       "  0.9599999785423279,\n",
       "  0.9606000185012817,\n",
       "  0.9614999890327454,\n",
       "  0.9613999724388123,\n",
       "  0.961899995803833,\n",
       "  0.9634000062942505,\n",
       "  0.9634000062942505,\n",
       "  0.9634000062942505,\n",
       "  0.965499997138977,\n",
       "  0.9646000266075134,\n",
       "  0.965499997138977,\n",
       "  0.9671000242233276,\n",
       "  0.9668999910354614,\n",
       "  0.9675999879837036,\n",
       "  0.9677000045776367,\n",
       "  0.9679999947547913,\n",
       "  0.9686999917030334,\n",
       "  0.9695000052452087,\n",
       "  0.9696000218391418,\n",
       "  0.9700999855995178,\n",
       "  0.9706000089645386,\n",
       "  0.9706000089645386,\n",
       "  0.9714999794960022,\n",
       "  0.9710999727249146,\n",
       "  0.9710999727249146,\n",
       "  0.9718000292778015]}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.296084</td>\n",
       "      <td>0.67540</td>\n",
       "      <td>0.611711</td>\n",
       "      <td>0.8692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.523693</td>\n",
       "      <td>0.87000</td>\n",
       "      <td>0.395837</td>\n",
       "      <td>0.9007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.399118</td>\n",
       "      <td>0.89274</td>\n",
       "      <td>0.331610</td>\n",
       "      <td>0.9110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.348641</td>\n",
       "      <td>0.90372</td>\n",
       "      <td>0.300960</td>\n",
       "      <td>0.9173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.318808</td>\n",
       "      <td>0.91076</td>\n",
       "      <td>0.280407</td>\n",
       "      <td>0.9215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.297489</td>\n",
       "      <td>0.91666</td>\n",
       "      <td>0.265267</td>\n",
       "      <td>0.9255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.280862</td>\n",
       "      <td>0.92164</td>\n",
       "      <td>0.251037</td>\n",
       "      <td>0.9298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.267347</td>\n",
       "      <td>0.92450</td>\n",
       "      <td>0.241613</td>\n",
       "      <td>0.9318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.255639</td>\n",
       "      <td>0.92778</td>\n",
       "      <td>0.231964</td>\n",
       "      <td>0.9344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.244825</td>\n",
       "      <td>0.93090</td>\n",
       "      <td>0.224994</td>\n",
       "      <td>0.9360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.235197</td>\n",
       "      <td>0.93378</td>\n",
       "      <td>0.216751</td>\n",
       "      <td>0.9393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.226608</td>\n",
       "      <td>0.93664</td>\n",
       "      <td>0.210619</td>\n",
       "      <td>0.9411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.218412</td>\n",
       "      <td>0.93822</td>\n",
       "      <td>0.204121</td>\n",
       "      <td>0.9421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.210803</td>\n",
       "      <td>0.94116</td>\n",
       "      <td>0.196435</td>\n",
       "      <td>0.9451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.203713</td>\n",
       "      <td>0.94272</td>\n",
       "      <td>0.191386</td>\n",
       "      <td>0.9464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.196777</td>\n",
       "      <td>0.94528</td>\n",
       "      <td>0.187149</td>\n",
       "      <td>0.9488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.190595</td>\n",
       "      <td>0.94634</td>\n",
       "      <td>0.180806</td>\n",
       "      <td>0.9515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.184461</td>\n",
       "      <td>0.94808</td>\n",
       "      <td>0.176129</td>\n",
       "      <td>0.9524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.178583</td>\n",
       "      <td>0.95006</td>\n",
       "      <td>0.173183</td>\n",
       "      <td>0.9537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.173088</td>\n",
       "      <td>0.95176</td>\n",
       "      <td>0.167269</td>\n",
       "      <td>0.9542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.168112</td>\n",
       "      <td>0.95254</td>\n",
       "      <td>0.164268</td>\n",
       "      <td>0.9559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.163133</td>\n",
       "      <td>0.95416</td>\n",
       "      <td>0.159860</td>\n",
       "      <td>0.9573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.158576</td>\n",
       "      <td>0.95542</td>\n",
       "      <td>0.155785</td>\n",
       "      <td>0.9582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.153896</td>\n",
       "      <td>0.95642</td>\n",
       "      <td>0.153346</td>\n",
       "      <td>0.9593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.149583</td>\n",
       "      <td>0.95768</td>\n",
       "      <td>0.150391</td>\n",
       "      <td>0.9600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.145641</td>\n",
       "      <td>0.95904</td>\n",
       "      <td>0.147245</td>\n",
       "      <td>0.9606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.141782</td>\n",
       "      <td>0.96056</td>\n",
       "      <td>0.144866</td>\n",
       "      <td>0.9615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.138088</td>\n",
       "      <td>0.96150</td>\n",
       "      <td>0.141222</td>\n",
       "      <td>0.9614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.134402</td>\n",
       "      <td>0.96224</td>\n",
       "      <td>0.139549</td>\n",
       "      <td>0.9619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.130977</td>\n",
       "      <td>0.96294</td>\n",
       "      <td>0.137313</td>\n",
       "      <td>0.9634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.127791</td>\n",
       "      <td>0.96370</td>\n",
       "      <td>0.134323</td>\n",
       "      <td>0.9634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.124705</td>\n",
       "      <td>0.96506</td>\n",
       "      <td>0.131863</td>\n",
       "      <td>0.9634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.121741</td>\n",
       "      <td>0.96544</td>\n",
       "      <td>0.130297</td>\n",
       "      <td>0.9655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.118780</td>\n",
       "      <td>0.96686</td>\n",
       "      <td>0.128070</td>\n",
       "      <td>0.9646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.116047</td>\n",
       "      <td>0.96748</td>\n",
       "      <td>0.126001</td>\n",
       "      <td>0.9655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.113482</td>\n",
       "      <td>0.96792</td>\n",
       "      <td>0.124254</td>\n",
       "      <td>0.9671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.110881</td>\n",
       "      <td>0.96892</td>\n",
       "      <td>0.122193</td>\n",
       "      <td>0.9669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.108291</td>\n",
       "      <td>0.96910</td>\n",
       "      <td>0.121851</td>\n",
       "      <td>0.9676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.105956</td>\n",
       "      <td>0.97032</td>\n",
       "      <td>0.120460</td>\n",
       "      <td>0.9677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.103633</td>\n",
       "      <td>0.97126</td>\n",
       "      <td>0.117865</td>\n",
       "      <td>0.9680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.101303</td>\n",
       "      <td>0.97164</td>\n",
       "      <td>0.116331</td>\n",
       "      <td>0.9687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.099171</td>\n",
       "      <td>0.97204</td>\n",
       "      <td>0.114335</td>\n",
       "      <td>0.9695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.097043</td>\n",
       "      <td>0.97272</td>\n",
       "      <td>0.113299</td>\n",
       "      <td>0.9696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.094983</td>\n",
       "      <td>0.97368</td>\n",
       "      <td>0.113110</td>\n",
       "      <td>0.9701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.093050</td>\n",
       "      <td>0.97400</td>\n",
       "      <td>0.110745</td>\n",
       "      <td>0.9706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.091074</td>\n",
       "      <td>0.97458</td>\n",
       "      <td>0.109832</td>\n",
       "      <td>0.9706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.089220</td>\n",
       "      <td>0.97556</td>\n",
       "      <td>0.108850</td>\n",
       "      <td>0.9715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.087480</td>\n",
       "      <td>0.97604</td>\n",
       "      <td>0.108075</td>\n",
       "      <td>0.9711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.085815</td>\n",
       "      <td>0.97648</td>\n",
       "      <td>0.108127</td>\n",
       "      <td>0.9711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.084080</td>\n",
       "      <td>0.97682</td>\n",
       "      <td>0.106234</td>\n",
       "      <td>0.9718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  accuracy  val_loss  val_accuracy\n",
       "0   1.296084   0.67540  0.611711        0.8692\n",
       "1   0.523693   0.87000  0.395837        0.9007\n",
       "2   0.399118   0.89274  0.331610        0.9110\n",
       "3   0.348641   0.90372  0.300960        0.9173\n",
       "4   0.318808   0.91076  0.280407        0.9215\n",
       "5   0.297489   0.91666  0.265267        0.9255\n",
       "6   0.280862   0.92164  0.251037        0.9298\n",
       "7   0.267347   0.92450  0.241613        0.9318\n",
       "8   0.255639   0.92778  0.231964        0.9344\n",
       "9   0.244825   0.93090  0.224994        0.9360\n",
       "10  0.235197   0.93378  0.216751        0.9393\n",
       "11  0.226608   0.93664  0.210619        0.9411\n",
       "12  0.218412   0.93822  0.204121        0.9421\n",
       "13  0.210803   0.94116  0.196435        0.9451\n",
       "14  0.203713   0.94272  0.191386        0.9464\n",
       "15  0.196777   0.94528  0.187149        0.9488\n",
       "16  0.190595   0.94634  0.180806        0.9515\n",
       "17  0.184461   0.94808  0.176129        0.9524\n",
       "18  0.178583   0.95006  0.173183        0.9537\n",
       "19  0.173088   0.95176  0.167269        0.9542\n",
       "20  0.168112   0.95254  0.164268        0.9559\n",
       "21  0.163133   0.95416  0.159860        0.9573\n",
       "22  0.158576   0.95542  0.155785        0.9582\n",
       "23  0.153896   0.95642  0.153346        0.9593\n",
       "24  0.149583   0.95768  0.150391        0.9600\n",
       "25  0.145641   0.95904  0.147245        0.9606\n",
       "26  0.141782   0.96056  0.144866        0.9615\n",
       "27  0.138088   0.96150  0.141222        0.9614\n",
       "28  0.134402   0.96224  0.139549        0.9619\n",
       "29  0.130977   0.96294  0.137313        0.9634\n",
       "30  0.127791   0.96370  0.134323        0.9634\n",
       "31  0.124705   0.96506  0.131863        0.9634\n",
       "32  0.121741   0.96544  0.130297        0.9655\n",
       "33  0.118780   0.96686  0.128070        0.9646\n",
       "34  0.116047   0.96748  0.126001        0.9655\n",
       "35  0.113482   0.96792  0.124254        0.9671\n",
       "36  0.110881   0.96892  0.122193        0.9669\n",
       "37  0.108291   0.96910  0.121851        0.9676\n",
       "38  0.105956   0.97032  0.120460        0.9677\n",
       "39  0.103633   0.97126  0.117865        0.9680\n",
       "40  0.101303   0.97164  0.116331        0.9687\n",
       "41  0.099171   0.97204  0.114335        0.9695\n",
       "42  0.097043   0.97272  0.113299        0.9696\n",
       "43  0.094983   0.97368  0.113110        0.9701\n",
       "44  0.093050   0.97400  0.110745        0.9706\n",
       "45  0.091074   0.97458  0.109832        0.9706\n",
       "46  0.089220   0.97556  0.108850        0.9715\n",
       "47  0.087480   0.97604  0.108075        0.9711\n",
       "48  0.085815   0.97648  0.108127        0.9711\n",
       "49  0.084080   0.97682  0.106234        0.9718"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si el modelo no ha ido bien, prueba a cambiar el learning rate, cambia de optimizador y después prueba a cambiar capas, neuronas y funciones de activación.\n",
    "\n",
    "Ya tenemos el modelo entrenado. Probémoslo con test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0916 - accuracy: 0.9707\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09164878726005554, 0.9707000255584717]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\misla\\AppData\\Local\\Temp\\ipykernel_11448\\1468152043.py:2: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  plt.imshow(X_test[0].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cogemos el primero\n",
    "plt.imshow(X_test[0].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.32941177, 0.7254902 , 0.62352943, 0.5921569 ,\n",
       "         0.23529412, 0.14117648, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.87058824, 0.99607843, 0.99607843, 0.99607843,\n",
       "         0.99607843, 0.94509804, 0.7764706 , 0.7764706 , 0.7764706 ,\n",
       "         0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 ,\n",
       "         0.6666667 , 0.20392157, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.2627451 , 0.44705883, 0.28235295, 0.44705883,\n",
       "         0.6392157 , 0.8901961 , 0.99607843, 0.88235295, 0.99607843,\n",
       "         0.99607843, 0.99607843, 0.98039216, 0.8980392 , 0.99607843,\n",
       "         0.99607843, 0.54901963, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.06666667, 0.25882354, 0.05490196, 0.2627451 ,\n",
       "         0.2627451 , 0.2627451 , 0.23137255, 0.08235294, 0.9254902 ,\n",
       "         0.99607843, 0.41568628, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.3254902 , 0.99215686,\n",
       "         0.81960785, 0.07058824, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.08627451, 0.9137255 , 1.        ,\n",
       "         0.3254902 , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.5058824 , 0.99607843, 0.93333334,\n",
       "         0.17254902, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.23137255, 0.9764706 , 0.99607843, 0.24313726,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.52156866, 0.99607843, 0.73333335, 0.01960784,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.03529412, 0.8039216 , 0.972549  , 0.22745098, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.49411765, 0.99607843, 0.7137255 , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.29411766,\n",
       "         0.9843137 , 0.9411765 , 0.22352941, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.07450981, 0.8666667 ,\n",
       "         0.99607843, 0.6509804 , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.01176471, 0.79607844, 0.99607843,\n",
       "         0.85882354, 0.13725491, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.14901961, 0.99607843, 0.99607843,\n",
       "         0.3019608 , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.12156863, 0.8784314 , 0.99607843, 0.4509804 ,\n",
       "         0.00392157, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.52156866, 0.99607843, 0.99607843, 0.20392157,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.23921569, 0.9490196 , 0.99607843, 0.99607843, 0.20392157,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.4745098 , 0.99607843, 0.99607843, 0.85882354, 0.15686275,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.4745098 , 0.99607843, 0.8117647 , 0.07058824, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 183ms/step\n",
      "(1, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2.0264211e-05, 3.1816930e-07, 5.8296125e-04, 3.8260527e-04,\n",
       "        1.2047506e-07, 2.0819543e-05, 1.0372267e-09, 9.9893886e-01,\n",
       "        9.6078129e-06, 4.4377295e-05]], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test[:1])\n",
    "print(predictions.shape)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 26/313 [=>............................] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=int64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\misla\\AppData\\Local\\Temp\\ipykernel_13392\\1084033691.py:1: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  plt.imshow(X_test[2].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[2].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema de regresión\n",
    "Veamos un ejemplo de cómo aplicar una red neuronal de TensorFlow a un problema de regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  target  \n",
       "0    -122.23   4.526  \n",
       "1    -122.22   3.585  \n",
       "2    -122.24   3.521  \n",
       "3    -122.25   3.413  \n",
       "4    -122.25   3.422  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargamos datos\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "df = pd.DataFrame(housing.data, columns = housing.feature_names)\n",
    "df['target'] = housing['target']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divimos en train, test y validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data,\n",
    "                                                              housing.target)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full,\n",
    "                                                      y_train_full)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11610, 8)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montamos el modelo. Simplemente se compondrá de una hidden layer, a la que le configuramos una capa previa de entrada de 8 neuronas (las features).\n",
    "\n",
    "Se trata de un modelo de regresión, por lo que la capa de salida es una única neurona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "362.8125"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "11610/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11610, 8)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7636 - val_loss: 0.6107\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5912 - val_loss: 0.7273\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7317 - val_loss: 0.4578\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4643 - val_loss: 0.4579\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4463 - val_loss: 0.4278\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4327 - val_loss: 0.4189\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4250 - val_loss: 0.4124\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4227 - val_loss: 0.4118\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4188 - val_loss: 0.4040\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4240 - val_loss: 0.4078\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4458 - val_loss: 0.4031\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4097 - val_loss: 0.3981\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4026 - val_loss: 0.3987\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3996 - val_loss: 0.3984\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4142 - val_loss: 0.3924\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3978 - val_loss: 0.3867\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3953 - val_loss: 0.3888\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3955 - val_loss: 0.3847\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3892 - val_loss: 0.3832\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3880 - val_loss: 0.3836\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation = 'relu',\n",
    "                      input_shape = X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss = \"mean_squared_error\",\n",
    "             optimizer = \"sgd\")\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs = 20,\n",
    "                   validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "270"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8*30 + 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_5 (Dense)             (None, 30)                270       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 31        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 301 (1.18 KB)\n",
      "Trainable params: 301 (1.18 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 1ms/step - loss: 0.3814\n",
      "0.381396621465683\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate(X_test, y_test)\n",
    "print(mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 60ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.39081573],\n",
       "       [2.1586773 ],\n",
       "       [3.351023  ],\n",
       "       [2.1935925 ],\n",
       "       [2.0204966 ]], dtype=float32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test[:5])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar modelo\n",
    "Para guardar el modelo, en el formato de Keras (HDF5). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\misla\\.pyenv\\pyenv-win\\versions\\3.10.2\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo volvemos a cargar\n",
    "model = keras.models.load_model(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 51ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.39081573],\n",
       "       [2.1586773 ],\n",
       "       [3.351023  ],\n",
       "       [2.1935925 ],\n",
       "       [2.0204966 ],\n",
       "       [1.6700888 ],\n",
       "       [2.197114  ],\n",
       "       [1.2360029 ],\n",
       "       [1.4039186 ],\n",
       "       [0.5936197 ]], dtype=float32)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks\n",
    "Son funciones predefinidas de Keras a aplicar durante el entrenamiento\n",
    "Por ejemplo, `ModelCheckpoint` sirve para que el modelo se vaya guardando tras cada epoch. Así no perdemos el progreso en caso de que decidamos interrumpir el entrenamiento. El callback recibe como argumento el nombre del objeto donde queremos que se guarde el modelo entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3844\n",
      "Epoch 2/30\n",
      " 84/363 [=====>........................] - ETA: 0s - loss: 0.3361"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\misla\\.pyenv\\pyenv-win\\versions\\3.10.2\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3943\n",
      "Epoch 3/30\n",
      "203/363 [===============>..............] - ETA: 0s - loss: 0.3841"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\misla\\Documents\\Bootcamp\\DS_TheBridgeBBK_SBIL2023\\3-Machine_Learning\\3-Deep_Learning\\1-Intro Deep Learning\\2-Keras.ipynb Cell 88\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/misla/Documents/Bootcamp/DS_TheBridgeBBK_SBIL2023/3-Machine_Learning/3-Deep_Learning/1-Intro%20Deep%20Learning/2-Keras.ipynb#Y145sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m checkpoint_cb \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mModelCheckpoint(\u001b[39m\"\u001b[39m\u001b[39mcallback_model.h5\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/misla/Documents/Bootcamp/DS_TheBridgeBBK_SBIL2023/3-Machine_Learning/3-Deep_Learning/1-Intro%20Deep%20Learning/2-Keras.ipynb#Y145sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X_train,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/misla/Documents/Bootcamp/DS_TheBridgeBBK_SBIL2023/3-Machine_Learning/3-Deep_Learning/1-Intro%20Deep%20Learning/2-Keras.ipynb#Y145sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                    y_train,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/misla/Documents/Bootcamp/DS_TheBridgeBBK_SBIL2023/3-Machine_Learning/3-Deep_Learning/1-Intro%20Deep%20Learning/2-Keras.ipynb#Y145sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                    epochs\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/misla/Documents/Bootcamp/DS_TheBridgeBBK_SBIL2023/3-Machine_Learning/3-Deep_Learning/1-Intro%20Deep%20Learning/2-Keras.ipynb#Y145sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                    callbacks \u001b[39m=\u001b[39;49m [checkpoint_cb])\n",
      "File \u001b[1;32mc:\\Users\\misla\\.pyenv\\pyenv-win\\versions\\3.10.2\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\misla\\.pyenv\\pyenv-win\\versions\\3.10.2\\lib\\site-packages\\keras\\src\\engine\\training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1734\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1735\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1736\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1739\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1740\u001b[0m ):\n\u001b[0;32m   1741\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1742\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1743\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1744\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\misla\\.pyenv\\pyenv-win\\versions\\3.10.2\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\misla\\.pyenv\\pyenv-win\\versions\\3.10.2\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    822\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    824\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 825\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    827\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    828\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\misla\\.pyenv\\pyenv-win\\versions\\3.10.2\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:864\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    862\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    863\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 864\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    865\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[0;32m    866\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    867\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\misla\\.pyenv\\pyenv-win\\versions\\3.10.2\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    146\u001b[0m   (concrete_function,\n\u001b[0;32m    147\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 148\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\misla\\.pyenv\\pyenv-win\\versions\\3.10.2\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs)\u001b[0m\n\u001b[0;32m   1345\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1346\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1347\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1348\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1349\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function(\u001b[39m*\u001b[39;49margs))\n\u001b[0;32m   1350\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1351\u001b[0m     args,\n\u001b[0;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1353\u001b[0m     executing_eagerly)\n\u001b[0;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\misla\\.pyenv\\pyenv-win\\versions\\3.10.2\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[0;32m    195\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 196\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[0;32m    197\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[0;32m    198\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[0;32m    199\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[0;32m    200\u001b[0m     )\n\u001b[0;32m    201\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\u001b[39mself\u001b[39m, \u001b[39mlist\u001b[39m(args))\n",
      "File \u001b[1;32mc:\\Users\\misla\\.pyenv\\pyenv-win\\versions\\3.10.2\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1455\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[0;32m   1456\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m   1458\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1459\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[0;32m   1460\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[0;32m   1461\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m   1462\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1463\u001b[0m   )\n\u001b[0;32m   1464\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1465\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1466\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m   1467\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1471\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[0;32m   1472\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\misla\\.pyenv\\pyenv-win\\versions\\3.10.2\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"callback_model.h5\")\n",
    "history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs=30,\n",
    "                   callbacks = [checkpoint_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"callback_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 0s 865us/step - loss: 0.3080\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3080047070980072"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopping\n",
    "Interrumpe el entrenamiento cuando no ve progreso en el set de validación. Para ello tiene en cuenta un numero de epochs llamado `patience`. Se puede combinar con el callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_cbprueba = keras.callbacks.ModelCheckpoint(\"early_checkpoint.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3394 - val_loss: 0.3316\n",
      "Epoch 2/50\n",
      " 81/363 [=====>........................] - ETA: 0s - loss: 0.3654"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\misla\\.pyenv\\pyenv-win\\versions\\3.10.2\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3380 - val_loss: 0.3310\n",
      "Epoch 3/50\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3373 - val_loss: 0.3399\n",
      "Epoch 4/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3385 - val_loss: 0.3282\n",
      "Epoch 5/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3383 - val_loss: 0.3345\n",
      "Epoch 6/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3353 - val_loss: 0.3309\n",
      "Epoch 7/50\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3382 - val_loss: 0.3314\n",
      "Epoch 8/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3344 - val_loss: 0.3330\n",
      "Epoch 9/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3335 - val_loss: 0.3303\n"
     ]
    }
   ],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=5)\n",
    "history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs=50,\n",
    "                   validation_data = (X_valid, y_valid),\n",
    "                   callbacks = [early_stopping_cb, checkpoint_cbprueba])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "90139cb9a825bf3d63f6f6704e828dbd1ff7edbd4d0c6e906a71235d6efc74af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
